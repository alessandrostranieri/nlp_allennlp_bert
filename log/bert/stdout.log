2019-04-25 19:44:25,803 - INFO - allennlp.common.params - evaluate_on_test = False
2019-04-25 19:44:25,804 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'tokens': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}, 'type': 'sst_tokens'} and extras set()
2019-04-25 19:44:25,809 - INFO - allennlp.common.params - dataset_reader.type = sst_tokens
2019-04-25 19:44:25,810 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.stanford_sentiment_tree_bank.StanfordSentimentTreeBankDatasetReader'> from params {'token_indexers': {'tokens': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}} and extras set()
2019-04-25 19:44:25,837 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'} and extras set()
2019-04-25 19:44:25,840 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = bert-pretrained
2019-04-25 19:44:25,844 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'pretrained_model': 'bert-base-uncased'} and extras set()
2019-04-25 19:44:25,846 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.pretrained_model = bert-base-uncased
2019-04-25 19:44:25,846 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.use_starting_offsets = False
2019-04-25 19:44:25,847 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.do_lowercase = True
2019-04-25 19:44:25,853 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.never_lowercase = None
2019-04-25 19:44:25,856 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_pieces = 512
2019-04-25 19:44:26,480 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/astranieri/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-04-25 19:44:26,522 - INFO - allennlp.common.params - dataset_reader.use_subtrees = False
2019-04-25 19:44:26,523 - INFO - allennlp.common.params - dataset_reader.granularity = 5-class
2019-04-25 19:44:26,524 - INFO - allennlp.common.params - dataset_reader.lazy = False
2019-04-25 19:44:26,525 - INFO - allennlp.common.params - validation_dataset_reader = None
2019-04-25 19:44:26,526 - INFO - allennlp.common.params - train_data_path = data/stanfordSentimentTreebank/trees/train.txt
2019-04-25 19:44:26,527 - INFO - allennlp.training.util - Reading training data from data/stanfordSentimentTreebank/trees/train.txt
2019-04-25 19:44:26,532 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: data/stanfordSentimentTreebank/trees/train.txt
2019-04-25 19:44:27,948 - INFO - allennlp.common.params - validation_data_path = data/stanfordSentimentTreebank/trees/dev.txt
2019-04-25 19:44:27,949 - INFO - allennlp.training.util - Reading validation data from data/stanfordSentimentTreebank/trees/dev.txt
2019-04-25 19:44:27,953 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: data/stanfordSentimentTreebank/trees/dev.txt
2019-04-25 19:44:28,111 - INFO - allennlp.common.params - test_data_path = None
2019-04-25 19:44:28,112 - INFO - allennlp.training.trainer - From dataset instances, train, validation will be considered for vocabulary creation.
2019-04-25 19:44:28,113 - INFO - allennlp.common.params - vocabulary.type = None
2019-04-25 19:44:28,114 - INFO - allennlp.common.params - vocabulary.extend = False
2019-04-25 19:44:28,115 - INFO - allennlp.common.params - vocabulary.directory_path = None
2019-04-25 19:44:28,116 - INFO - allennlp.common.params - vocabulary.min_count = None
2019-04-25 19:44:28,116 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2019-04-25 19:44:28,117 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2019-04-25 19:44:28,119 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2019-04-25 19:44:28,121 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2019-04-25 19:44:28,125 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2019-04-25 19:44:28,126 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2019-04-25 19:44:28,170 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'encoder': {'hidden_size': 128, 'input_size': 768, 'type': 'lstm'}, 'type': 'lstm_classifier', 'word_embeddings': {'allow_unmatched_keys': True, 'tokens': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}} and extras {'vocab'}
2019-04-25 19:44:28,172 - INFO - allennlp.common.params - model.type = lstm_classifier
2019-04-25 19:44:28,173 - INFO - allennlp.common.from_params - instantiating class <class 'examples.sentiment.sst_classifier.LstmClassifier'> from params {'encoder': {'hidden_size': 128, 'input_size': 768, 'type': 'lstm'}, 'word_embeddings': {'allow_unmatched_keys': True, 'tokens': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}} and extras {'vocab'}
2019-04-25 19:44:28,175 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'tokens': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}} and extras {'vocab'}
2019-04-25 19:44:28,176 - INFO - allennlp.common.params - model.word_embeddings.type = basic
2019-04-25 19:44:28,178 - INFO - allennlp.common.params - model.word_embeddings.embedder_to_indexer_map = None
2019-04-25 19:44:28,179 - INFO - allennlp.common.params - model.word_embeddings.allow_unmatched_keys = True
2019-04-25 19:44:28,181 - INFO - allennlp.common.params - model.word_embeddings.token_embedders = None
2019-04-25 19:44:28,185 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'} and extras {'vocab'}
2019-04-25 19:44:28,189 - INFO - allennlp.common.params - model.word_embeddings.tokens.type = bert-pretrained
2019-04-25 19:44:28,191 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-uncased'} and extras {'vocab'}
2019-04-25 19:44:28,196 - INFO - allennlp.common.params - model.word_embeddings.tokens.pretrained_model = bert-base-uncased
2019-04-25 19:44:28,197 - INFO - allennlp.common.params - model.word_embeddings.tokens.requires_grad = False
2019-04-25 19:44:28,198 - INFO - allennlp.common.params - model.word_embeddings.tokens.top_layer_only = False
2019-04-25 19:44:28,838 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/astranieri/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2019-04-25 19:44:28,841 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /home/astranieri/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpebl3iti3
2019-04-25 19:44:32,880 - INFO - pytorch_pretrained_bert.modeling - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2019-04-25 19:44:35,755 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'hidden_size': 128, 'input_size': 768, 'type': 'lstm'} and extras {'vocab'}
2019-04-25 19:44:35,758 - INFO - allennlp.common.params - model.encoder.type = lstm
2019-04-25 19:44:35,762 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-04-25 19:44:35,763 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-04-25 19:44:35,764 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-04-25 19:44:35,765 - INFO - allennlp.common.params - model.encoder.hidden_size = 128
2019-04-25 19:44:35,765 - INFO - allennlp.common.params - model.encoder.input_size = 768
2019-04-25 19:44:35,767 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-04-25 19:44:35,774 - INFO - allennlp.common.params - model.positive_label = 4
2019-04-25 19:44:35,807 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()
2019-04-25 19:44:35,815 - INFO - allennlp.common.params - iterator.type = bucket
2019-04-25 19:44:35,817 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()
2019-04-25 19:44:35,821 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]
2019-04-25 19:44:35,823 - INFO - allennlp.common.params - iterator.padding_noise = 0.1
2019-04-25 19:44:35,831 - INFO - allennlp.common.params - iterator.biggest_batch_first = False
2019-04-25 19:44:35,832 - INFO - allennlp.common.params - iterator.batch_size = 32
2019-04-25 19:44:35,836 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2019-04-25 19:44:35,837 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None
2019-04-25 19:44:35,838 - INFO - allennlp.common.params - iterator.cache_instances = False
2019-04-25 19:44:35,842 - INFO - allennlp.common.params - iterator.track_epoch = False
2019-04-25 19:44:35,843 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2019-04-25 19:44:35,850 - INFO - allennlp.common.params - validation_iterator = None
2019-04-25 19:44:35,853 - INFO - allennlp.common.params - trainer.no_grad = ()
2019-04-25 19:44:35,857 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):
2019-04-25 19:44:35,858 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.word_embeddings.weight
2019-04-25 19:44:35,860 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.position_embeddings.weight
2019-04-25 19:44:35,865 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.token_type_embeddings.weight
2019-04-25 19:44:35,866 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.LayerNorm.weight
2019-04-25 19:44:35,870 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.LayerNorm.bias
2019-04-25 19:44:35,871 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.query.weight
2019-04-25 19:44:35,872 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.query.bias
2019-04-25 19:44:35,877 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.key.weight
2019-04-25 19:44:35,883 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.key.bias
2019-04-25 19:44:35,884 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.value.weight
2019-04-25 19:44:35,887 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.value.bias
2019-04-25 19:44:35,889 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.dense.weight
2019-04-25 19:44:35,893 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.dense.bias
2019-04-25 19:44:35,894 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2019-04-25 19:44:35,896 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2019-04-25 19:44:35,900 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.intermediate.dense.weight
2019-04-25 19:44:35,901 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.intermediate.dense.bias
2019-04-25 19:44:35,905 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.dense.weight
2019-04-25 19:44:35,906 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.dense.bias
2019-04-25 19:44:35,907 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.LayerNorm.weight
2019-04-25 19:44:35,909 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.LayerNorm.bias
2019-04-25 19:44:35,915 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.query.weight
2019-04-25 19:44:35,918 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.query.bias
2019-04-25 19:44:35,919 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.key.weight
2019-04-25 19:44:35,920 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.key.bias
2019-04-25 19:44:35,921 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.value.weight
2019-04-25 19:44:35,925 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.value.bias
2019-04-25 19:44:35,927 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.dense.weight
2019-04-25 19:44:35,935 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.dense.bias
2019-04-25 19:44:35,937 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2019-04-25 19:44:35,941 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2019-04-25 19:44:35,942 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.intermediate.dense.weight
2019-04-25 19:44:35,943 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.intermediate.dense.bias
2019-04-25 19:44:35,949 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.dense.weight
2019-04-25 19:44:35,951 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.dense.bias
2019-04-25 19:44:35,954 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.LayerNorm.weight
2019-04-25 19:44:35,955 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.LayerNorm.bias
2019-04-25 19:44:35,957 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.query.weight
2019-04-25 19:44:35,960 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.query.bias
2019-04-25 19:44:35,966 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.key.weight
2019-04-25 19:44:35,967 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.key.bias
2019-04-25 19:44:35,969 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.value.weight
2019-04-25 19:44:35,972 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.value.bias
2019-04-25 19:44:35,977 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.dense.weight
2019-04-25 19:44:35,979 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.dense.bias
2019-04-25 19:44:35,983 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2019-04-25 19:44:35,984 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2019-04-25 19:44:35,987 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.intermediate.dense.weight
2019-04-25 19:44:35,989 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.intermediate.dense.bias
2019-04-25 19:44:35,990 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.dense.weight
2019-04-25 19:44:35,995 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.dense.bias
2019-04-25 19:44:36,000 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.LayerNorm.weight
2019-04-25 19:44:36,001 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.LayerNorm.bias
2019-04-25 19:44:36,002 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.query.weight
2019-04-25 19:44:36,006 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.query.bias
2019-04-25 19:44:36,007 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.key.weight
2019-04-25 19:44:36,010 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.key.bias
2019-04-25 19:44:36,012 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.value.weight
2019-04-25 19:44:36,017 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.value.bias
2019-04-25 19:44:36,018 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.dense.weight
2019-04-25 19:44:36,021 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.dense.bias
2019-04-25 19:44:36,022 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2019-04-25 19:44:36,024 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2019-04-25 19:44:36,025 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.intermediate.dense.weight
2019-04-25 19:44:36,032 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.intermediate.dense.bias
2019-04-25 19:44:36,033 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.dense.weight
2019-04-25 19:44:36,035 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.dense.bias
2019-04-25 19:44:36,036 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.LayerNorm.weight
2019-04-25 19:44:36,037 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.LayerNorm.bias
2019-04-25 19:44:36,041 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.query.weight
2019-04-25 19:44:36,047 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.query.bias
2019-04-25 19:44:36,049 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.key.weight
2019-04-25 19:44:36,053 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.key.bias
2019-04-25 19:44:36,056 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.value.weight
2019-04-25 19:44:36,058 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.value.bias
2019-04-25 19:44:36,059 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.dense.weight
2019-04-25 19:44:36,065 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.dense.bias
2019-04-25 19:44:36,066 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2019-04-25 19:44:36,070 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2019-04-25 19:44:36,071 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.intermediate.dense.weight
2019-04-25 19:44:36,072 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.intermediate.dense.bias
2019-04-25 19:44:36,073 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.dense.weight
2019-04-25 19:44:36,080 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.dense.bias
2019-04-25 19:44:36,082 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.LayerNorm.weight
2019-04-25 19:44:36,083 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.LayerNorm.bias
2019-04-25 19:44:36,084 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.query.weight
2019-04-25 19:44:36,086 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.query.bias
2019-04-25 19:44:36,090 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.key.weight
2019-04-25 19:44:36,091 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.key.bias
2019-04-25 19:44:36,095 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.value.weight
2019-04-25 19:44:36,097 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.value.bias
2019-04-25 19:44:36,098 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.dense.weight
2019-04-25 19:44:36,102 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.dense.bias
2019-04-25 19:44:36,104 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2019-04-25 19:44:36,108 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2019-04-25 19:44:36,109 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.intermediate.dense.weight
2019-04-25 19:44:36,114 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.intermediate.dense.bias
2019-04-25 19:44:36,115 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.dense.weight
2019-04-25 19:44:36,118 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.dense.bias
2019-04-25 19:44:36,119 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.LayerNorm.weight
2019-04-25 19:44:36,120 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.LayerNorm.bias
2019-04-25 19:44:36,121 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.query.weight
2019-04-25 19:44:36,125 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.query.bias
2019-04-25 19:44:36,132 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.key.weight
2019-04-25 19:44:36,133 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.key.bias
2019-04-25 19:44:36,136 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.value.weight
2019-04-25 19:44:36,137 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.value.bias
2019-04-25 19:44:36,141 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.dense.weight
2019-04-25 19:44:36,142 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.dense.bias
2019-04-25 19:44:36,143 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2019-04-25 19:44:36,149 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2019-04-25 19:44:36,150 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.intermediate.dense.weight
2019-04-25 19:44:36,153 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.intermediate.dense.bias
2019-04-25 19:44:36,155 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.dense.weight
2019-04-25 19:44:36,156 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.dense.bias
2019-04-25 19:44:36,157 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.LayerNorm.weight
2019-04-25 19:44:36,166 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.LayerNorm.bias
2019-04-25 19:44:36,168 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.query.weight
2019-04-25 19:44:36,169 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.query.bias
2019-04-25 19:44:36,170 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.key.weight
2019-04-25 19:44:36,173 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.key.bias
2019-04-25 19:44:36,175 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.value.weight
2019-04-25 19:44:36,179 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.value.bias
2019-04-25 19:44:36,181 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.dense.weight
2019-04-25 19:44:36,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.dense.bias
2019-04-25 19:44:36,186 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2019-04-25 19:44:36,187 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2019-04-25 19:44:36,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.intermediate.dense.weight
2019-04-25 19:44:36,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.intermediate.dense.bias
2019-04-25 19:44:36,192 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.dense.weight
2019-04-25 19:44:36,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.dense.bias
2019-04-25 19:44:36,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.LayerNorm.weight
2019-04-25 19:44:36,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.LayerNorm.bias
2019-04-25 19:44:36,205 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.query.weight
2019-04-25 19:44:36,206 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.query.bias
2019-04-25 19:44:36,207 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.key.weight
2019-04-25 19:44:36,208 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.key.bias
2019-04-25 19:44:36,213 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.value.weight
2019-04-25 19:44:36,215 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.value.bias
2019-04-25 19:44:36,217 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.dense.weight
2019-04-25 19:44:36,217 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.dense.bias
2019-04-25 19:44:36,218 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2019-04-25 19:44:36,219 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2019-04-25 19:44:36,219 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.intermediate.dense.weight
2019-04-25 19:44:36,220 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.intermediate.dense.bias
2019-04-25 19:44:36,221 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.dense.weight
2019-04-25 19:44:36,224 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.dense.bias
2019-04-25 19:44:36,227 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.LayerNorm.weight
2019-04-25 19:44:36,229 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.LayerNorm.bias
2019-04-25 19:44:36,231 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.query.weight
2019-04-25 19:44:36,232 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.query.bias
2019-04-25 19:44:36,234 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.key.weight
2019-04-25 19:44:36,235 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.key.bias
2019-04-25 19:44:36,238 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.value.weight
2019-04-25 19:44:36,239 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.value.bias
2019-04-25 19:44:36,240 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.dense.weight
2019-04-25 19:44:36,241 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.dense.bias
2019-04-25 19:44:36,242 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2019-04-25 19:44:36,247 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2019-04-25 19:44:36,248 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.intermediate.dense.weight
2019-04-25 19:44:36,250 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.intermediate.dense.bias
2019-04-25 19:44:36,251 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.dense.weight
2019-04-25 19:44:36,251 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.dense.bias
2019-04-25 19:44:36,252 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.LayerNorm.weight
2019-04-25 19:44:36,253 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.LayerNorm.bias
2019-04-25 19:44:36,256 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.query.weight
2019-04-25 19:44:36,260 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.query.bias
2019-04-25 19:44:36,261 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.key.weight
2019-04-25 19:44:36,262 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.key.bias
2019-04-25 19:44:36,266 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.value.weight
2019-04-25 19:44:36,267 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.value.bias
2019-04-25 19:44:36,270 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.dense.weight
2019-04-25 19:44:36,272 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.dense.bias
2019-04-25 19:44:36,273 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2019-04-25 19:44:36,273 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2019-04-25 19:44:36,281 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.intermediate.dense.weight
2019-04-25 19:44:36,283 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.intermediate.dense.bias
2019-04-25 19:44:36,284 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.dense.weight
2019-04-25 19:44:36,285 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.dense.bias
2019-04-25 19:44:36,286 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.LayerNorm.weight
2019-04-25 19:44:36,287 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.LayerNorm.bias
2019-04-25 19:44:36,291 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.query.weight
2019-04-25 19:44:36,295 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.query.bias
2019-04-25 19:44:36,297 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.key.weight
2019-04-25 19:44:36,299 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.key.bias
2019-04-25 19:44:36,299 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.value.weight
2019-04-25 19:44:36,300 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.value.bias
2019-04-25 19:44:36,305 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.dense.weight
2019-04-25 19:44:36,307 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.dense.bias
2019-04-25 19:44:36,308 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2019-04-25 19:44:36,309 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2019-04-25 19:44:36,310 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.intermediate.dense.weight
2019-04-25 19:44:36,313 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.intermediate.dense.bias
2019-04-25 19:44:36,314 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.dense.weight
2019-04-25 19:44:36,319 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.dense.bias
2019-04-25 19:44:36,320 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.LayerNorm.weight
2019-04-25 19:44:36,321 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.LayerNorm.bias
2019-04-25 19:44:36,323 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.pooler.dense.weight
2019-04-25 19:44:36,323 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.pooler.dense.bias
2019-04-25 19:44:36,327 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):
2019-04-25 19:44:36,328 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.gamma
2019-04-25 19:44:36,331 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.0
2019-04-25 19:44:36,333 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.1
2019-04-25 19:44:36,334 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.2
2019-04-25 19:44:36,337 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.3
2019-04-25 19:44:36,338 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.4
2019-04-25 19:44:36,339 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.5
2019-04-25 19:44:36,340 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.6
2019-04-25 19:44:36,341 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.7
2019-04-25 19:44:36,342 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.8
2019-04-25 19:44:36,347 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.9
2019-04-25 19:44:36,348 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.10
2019-04-25 19:44:36,350 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.11
2019-04-25 19:44:36,351 - INFO - allennlp.training.trainer - encoder._module.weight_ih_l0
2019-04-25 19:44:36,351 - INFO - allennlp.training.trainer - encoder._module.weight_hh_l0
2019-04-25 19:44:36,354 - INFO - allennlp.training.trainer - encoder._module.bias_ih_l0
2019-04-25 19:44:36,354 - INFO - allennlp.training.trainer - encoder._module.bias_hh_l0
2019-04-25 19:44:36,356 - INFO - allennlp.training.trainer - linear.weight
2019-04-25 19:44:36,360 - INFO - allennlp.training.trainer - linear.bias
2019-04-25 19:44:36,360 - INFO - allennlp.common.params - trainer.patience = 5
2019-04-25 19:44:36,361 - INFO - allennlp.common.params - trainer.validation_metric = -loss
2019-04-25 19:44:36,365 - INFO - allennlp.common.params - trainer.shuffle = True
2019-04-25 19:44:36,367 - INFO - allennlp.common.params - trainer.num_epochs = 20
2019-04-25 19:44:36,368 - INFO - allennlp.common.params - trainer.cuda_device = -1
2019-04-25 19:44:36,371 - INFO - allennlp.common.params - trainer.grad_norm = None
2019-04-25 19:44:36,372 - INFO - allennlp.common.params - trainer.grad_clipping = None
2019-04-25 19:44:36,372 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2019-04-25 19:44:36,374 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2019-04-25 19:44:36,375 - INFO - allennlp.common.params - trainer.optimizer = adam
2019-04-25 19:44:36,380 - INFO - allennlp.common.params - parameter_groups = None
2019-04-25 19:44:36,381 - INFO - allennlp.training.optimizers - Number of trainable parameters: 460434
2019-04-25 19:44:36,383 - INFO - allennlp.common.params - infer_type_and_cast = True
2019-04-25 19:44:36,384 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-04-25 19:44:36,385 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-04-25 19:44:36,386 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20
2019-04-25 19:44:36,387 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2019-04-25 19:44:36,388 - INFO - allennlp.common.params - trainer.model_save_interval = None
2019-04-25 19:44:36,390 - INFO - allennlp.common.params - trainer.summary_interval = 100
2019-04-25 19:44:36,393 - INFO - allennlp.common.params - trainer.histogram_interval = None
2019-04-25 19:44:36,394 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True
2019-04-25 19:44:36,395 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False
2019-04-25 19:44:36,399 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2019-04-25 19:44:36,459 - INFO - allennlp.training.trainer - Beginning training.
2019-04-25 19:44:36,460 - INFO - allennlp.training.trainer - Epoch 0/19
2019-04-25 19:44:36,461 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1138.416
2019-04-25 19:44:36,592 - INFO - allennlp.training.trainer - Training
2019-04-25 19:49:24,264 - INFO - allennlp.training.trainer - Validating
2019-04-25 19:49:56,886 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 19:49:56,886 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1138.416  |       N/A
2019-04-25 19:49:56,887 - INFO - allennlp.training.tensorboard_writer - loss          |     1.348  |     1.231
2019-04-25 19:49:56,888 - INFO - allennlp.training.tensorboard_writer - precision     |     0.383  |     0.591
2019-04-25 19:49:56,889 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.401  |     0.467
2019-04-25 19:49:56,890 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.174  |     0.161
2019-04-25 19:49:56,890 - INFO - allennlp.training.tensorboard_writer - recall        |     0.113  |     0.094
2019-04-25 19:49:57,345 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'sst-model-bert/best.th'.
2019-04-25 19:49:58,388 - INFO - allennlp.training.trainer - Epoch duration: 00:05:21
2019-04-25 19:49:58,388 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:41:56
2019-04-25 19:49:58,389 - INFO - allennlp.training.trainer - Epoch 1/19
2019-04-25 19:49:58,390 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1860.36
2019-04-25 19:49:58,618 - INFO - allennlp.training.trainer - Training
2019-04-25 19:54:39,953 - INFO - allennlp.training.trainer - Validating
2019-04-25 19:55:16,730 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 19:55:16,731 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1860.360  |       N/A
2019-04-25 19:55:16,731 - INFO - allennlp.training.tensorboard_writer - loss          |     1.145  |     1.219
2019-04-25 19:55:16,732 - INFO - allennlp.training.tensorboard_writer - precision     |     0.546  |     0.514
2019-04-25 19:55:16,733 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.508  |     0.460
2019-04-25 19:55:16,733 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.406  |     0.357
2019-04-25 19:55:16,734 - INFO - allennlp.training.tensorboard_writer - recall        |     0.323  |     0.273
2019-04-25 19:55:17,188 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'sst-model-bert/best.th'.
2019-04-25 19:55:18,163 - INFO - allennlp.training.trainer - Epoch duration: 00:05:19
2019-04-25 19:55:18,164 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:36:15
2019-04-25 19:55:18,166 - INFO - allennlp.training.trainer - Epoch 2/19
2019-04-25 19:55:18,167 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1862.756
2019-04-25 19:55:18,387 - INFO - allennlp.training.trainer - Training
2019-04-25 20:00:05,084 - INFO - allennlp.training.trainer - Validating
2019-04-25 20:00:39,618 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 20:00:39,618 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1862.756  |       N/A
2019-04-25 20:00:39,619 - INFO - allennlp.training.tensorboard_writer - loss          |     0.986  |     1.302
2019-04-25 20:00:39,620 - INFO - allennlp.training.tensorboard_writer - precision     |     0.624  |     0.393
2019-04-25 20:00:39,620 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.595  |     0.405
2019-04-25 20:00:39,621 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.544  |     0.455
2019-04-25 20:00:39,621 - INFO - allennlp.training.tensorboard_writer - recall        |     0.483  |     0.540
2019-04-25 20:00:40,009 - INFO - allennlp.training.trainer - Epoch duration: 00:05:21
2019-04-25 20:00:40,010 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:31:00
2019-04-25 20:00:40,011 - INFO - allennlp.training.trainer - Epoch 3/19
2019-04-25 20:00:40,012 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1862.756
2019-04-25 20:00:40,211 - INFO - allennlp.training.trainer - Training
2019-04-25 20:05:35,378 - INFO - allennlp.training.trainer - Validating
2019-04-25 20:06:09,681 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 20:06:09,682 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1862.756  |       N/A
2019-04-25 20:06:09,683 - INFO - allennlp.training.tensorboard_writer - loss          |     0.739  |     1.380
2019-04-25 20:06:09,684 - INFO - allennlp.training.tensorboard_writer - precision     |     0.725  |     0.404
2019-04-25 20:06:09,685 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.710  |     0.437
2019-04-25 20:06:09,686 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.683  |     0.346
2019-04-25 20:06:09,687 - INFO - allennlp.training.tensorboard_writer - recall        |     0.646  |     0.302
2019-04-25 20:06:10,206 - INFO - allennlp.training.trainer - Epoch duration: 00:05:30
2019-04-25 20:06:10,206 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:26:14
2019-04-25 20:06:10,207 - INFO - allennlp.training.trainer - Epoch 4/19
2019-04-25 20:06:10,208 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1864.956
2019-04-25 20:06:10,445 - INFO - allennlp.training.trainer - Training
2019-04-25 20:11:07,957 - INFO - allennlp.training.trainer - Validating
2019-04-25 20:11:45,610 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 20:11:45,610 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1864.956  |       N/A
2019-04-25 20:11:45,611 - INFO - allennlp.training.tensorboard_writer - loss          |     0.471  |     1.489
2019-04-25 20:11:45,611 - INFO - allennlp.training.tensorboard_writer - precision     |     0.872  |     0.392
2019-04-25 20:11:45,612 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.847  |     0.447
2019-04-25 20:11:45,612 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.852  |     0.322
2019-04-25 20:11:45,613 - INFO - allennlp.training.tensorboard_writer - recall        |     0.832  |     0.273
2019-04-25 20:11:46,117 - INFO - allennlp.training.trainer - Epoch duration: 00:05:35
2019-04-25 20:11:46,118 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:21:28
2019-04-25 20:11:46,120 - INFO - allennlp.training.trainer - Epoch 5/19
2019-04-25 20:11:46,120 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1864.956
2019-04-25 20:11:46,339 - INFO - allennlp.training.trainer - Training
2019-04-25 20:17:00,868 - INFO - allennlp.training.trainer - Validating
2019-04-25 20:17:39,417 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 20:17:39,418 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1864.956  |       N/A
2019-04-25 20:17:39,418 - INFO - allennlp.training.tensorboard_writer - loss          |     0.266  |     1.660
2019-04-25 20:17:39,419 - INFO - allennlp.training.tensorboard_writer - precision     |     0.948  |     0.387
2019-04-25 20:17:39,419 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.931  |     0.425
2019-04-25 20:17:39,420 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.941  |     0.437
2019-04-25 20:17:39,420 - INFO - allennlp.training.tensorboard_writer - recall        |     0.935  |     0.504
2019-04-25 20:17:39,937 - INFO - allennlp.training.trainer - Epoch duration: 00:05:53
2019-04-25 20:17:39,938 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:17:08
2019-04-25 20:17:39,939 - INFO - allennlp.training.trainer - Epoch 6/19
2019-04-25 20:17:39,941 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1864.956
2019-04-25 20:17:40,169 - INFO - allennlp.training.trainer - Training
2019-04-25 20:22:51,489 - INFO - allennlp.training.trainer - Validating
2019-04-25 20:23:27,397 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2019-04-25 20:23:27,398 - INFO - allennlp.training.checkpointer - loading best weights
